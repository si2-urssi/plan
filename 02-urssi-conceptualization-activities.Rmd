# URSSI Conceptualization {#section2}

The purpose of this conceptualization project was to create a roadmap for a US Research Software Sustainability Institute (URSSI).  The roadmap was to be informed by and responsive to a community of potential stakeholders, including researchers, software developers and users, funders, and program / product managers. To engage this diverse group of people and institutions we completed the described research in this section including a series of workshops, community outreach and communication, a survey, set of ethnographic studies, and a pilot Winter School for early-career researchers. At the conclusion of this section we offer a summary of the challenges identified, collectively, across all of the URSSI conceptualization activities, and what role we believe URSSI should play in addressing these challenges.

<center>
![FigName](images/conceptualization_activities.jpg)
</center>

## Workshops
 
**Community wide workshops**: In 2018 two community workshops were held with URSSI stakeholders in Berkeley (April) and Chicago (October). Participants were invited based on their ability to represent diverse roles, institutions, and perspectives on research software. The general goal of the two community workshops was to determine what topics this diverse group of stakeholders consider to be well-understood, where there is uncertainty or desire for guidance, and what work remains to be done in supporting sustainable research software. URSSI PIs facilitated broad discussions, and participated in small group breakout discussions. Additionally, participants at each workshop gave presentations about their on-going research software activities. 
 
**Thematic Workshops**: Participants at the first community workshop identified two topics that were worthy of more focused discussion and community input: Research software metrics, citation,  and impact evaluation; and, methods for incubating new and existing research software projects.  
 
* The **Metrics, Credit and Citation Workshop** was held in Santa Barbara, California January 2019. The 23 participants had strong expertise in the various workshop themes, including PIs of the CodeMeta project, Zenodo, and software credit initiatives such as SourceCred.
 
* The **Research Incubators Workshop** was held in College Park, Maryland in February 2019. There were 20 participants with strong expertise in research software project development, including program officers from various government agencies, open-source research software developers, and organizational scholars that have studied research software processes. 
 
**URSSI Design Workshop**: In April 2019 members of the Senior Personnel and Advisory Committees participated in a workshop in Chicago, IL. PIs presented preliminary results from our research (ethnographies and survey) as well as lessons learned from the four previously held URSSI workshops. 

## Website / Newsletter/ Blog

Since a major part of the conceptualization project was to build awareness of the need for an institute, our activities, and overall community interest, we used a [website](http://urssi.us), nine [newsletters](http://urssi.us/newsletter/), and 36 [blog posts](http://urssi.us/blog/) to do this, in addition to the PIs and others giving public talks and webinars about URSSI. The newsletters were mailing to a mailing list we developed of workshop attendees and subscribers, as well as advertised via an [URSSI twitter account](https://twitter.com/si2urssi/). The twitter account was also used to advertise the blog posts and newsletters, and currently has over 500 followers.

## Survey
 
We developed and disseminated a survey to compliment workshop participation. The primary goal of the survey is to gather the opinions, preferences, and self-reported activities of the research software community regarding development practices, development tools, training, funding/institutional support, career paths, credit for software work, and diversity/inclusion. For each of these topics, we asked a small number of general questions and then allowed participants to self-select to answer more detailed questions about any area of particular interest. We distributed the survey primarily to PIs of currently funded NSF and NIH projects, and in addition, the PIs distributed the survey to relevant mailing lists. The survey closed in May of 2019 after receiving approximately 1200 responses. 
 
The results of the survey highlighted some areas where URSSI could play a key role in advancing the sustainability of research software in the United States.

1. There was a mismatch between how respondents wanted to allocate their time and the actual allocation of time. This result provides an opportunity for URSSI to work with developers and teams to help them focus their efforts on the tasks that are most relevant.
2. The aspects of the software development process respondents viewed as being more difficult than they should be tended to focus on people-related activities rather than technical activities. This result suggests that URSSI could provide support to teams and developers by providing training and/or resources related to human factors in the software development process.
3. Respondents indicated they use a number of software development practices. However, one key practice that was underutilized is peer code review. URSSI can provide training on peer code review and work with teams to ensure that the infrastructure is in place to appropriately support this activity in the research software space.
4. The respondents indicated that software development practices including _requirements_, _design_, _maintenance_, and _documentation_ were not well-supported by tools.
5. In terms of version control, there is still a sizable percentage of people who use methods like _copying files to another location_ and _zip file backups_ as version control. This result suggests that URSSI could provide additional training and tools to help teams use modern version control systems.
6. Many of the items above relate to training activities. The results of the survey suggest that a large percentage of respondents have not received training in software development. While the respondents indicated there were sufficient opportunities for training, most of them suggested they did not have sufficient time for training. URSSI could help by providing training in different formats that work better with the demands of the research software developers’ environments.
7. Many respondents also found the level of support, in terms of funding, to be inadequate to be successful. URSSI could help by advocating both at the national funding level as well as at the University level for increased funding for important research software development activities.
8. Respondents also indicated their software contributions were not significantly valued in performance reviews. URSSI could help by developing and advocating for policies that help research software developers get adequate recognition for their work.
9. Most projects lack a formal diversity plan. URSSI could help in this respect by providing template diversity plans and support for developing appropriate ones for individual projects.

## Ethnography
 
To gain a deeper understanding of the practices and experiences of researchers who are actively engaged in software development, we have undertaken a series of ethnographic studies. These studies have focused on software projects of varying size and complexity in the field of hydrology, astronomy, and biochemistry. We have conducted observations, semi-structured interviews, and have gathered a series of archival documents to produce case studies of how, over time, these projects overcome challenges of recruiting contributors, building a governance model, seeking funding, and sharing credit in sustaining a software project that has demonstrable impact on a community of researchers.

Two of these studies, Astropy and Rosetta Commons, were developed as full case studies. Both projects face unique sustainability challenges that are solved somewhat differently, and while the main findings of this work are not novel in the sense that they will surprise anyone familiar with challenges to sustaining research software the value of this work is in comparing the two cases. By better understanding common approaches to overcoming sustainability challenges, we believe there is a valuable opportunity to abstract these approaches to models of success that can be modified or tailored by research software projects in other domains. A brief summary of the findings from these two case studies are below. 

Points of comparison:

* Distributed work coordination: Key to the success of both Astropy and Rosetta Commons is coordination of remote collaborative work. Astropy mirrors Python’s core development team in structuring contributor guidelines and supporting designated maintainers. Rosetta Commons differs substantially: the project employs four full-time infrastructure maintainers. This offloading of maintenance responsibilities frees up contributors (distributed labs throughout the USA) to focus on conducting research and driving innovations that extend Rosetta’s key functionality.    
* Funding: Astropy is fiscally sponsored by NumFocus, but depends upon grant funding from a variety of sources to sustain its collective work. A recent grant from Gordon and Betty Moore Foundation, “Sustaining and Growing the Astropy Project,” is focused exclusively on maintenance and governance for the project’s long-term viability to  practicing astronomers. Rosetta Commons combines licensing and grant funding to sustain its work. Licenses for commercial use and an NIH infrastructure maintenance grant have continuously supported the project since 2005.  
* Credit:  Both projects have had a number of papers published about their development. Astropy suggests two publications to cite when acknowledging use of the software [@robitaille2013astropy, @price2018astropy]. These two publications, combined, have received over 3000 citations. Rosetta Commons, because it has many versions. methods and language specific implementations, has no canonical citation. Interviews with contributors to Rosetta noted that this causes confusion for authors when rushing towards publication and many researchers have sought a centralized source they could acknowledge. Despite the lack of a canonical citation, two papers describing Rosetta and its use in predicting protein structures have, combined, received over 4300 citations [@rohl2004protein, @salmena2011cerna]. 


We observe differences in the two projects that seem marginal at first glance, but upon further analysis have important practical consequences for software development activities. For example, two substantial differences in the projects have consequences for the long-term sustainability of each project: 

* Astropy, in following an open model of contribution, focuses time and attention on clearly documenting and making contributor guidelines accessible to research software engineers. Effort of the maintenance team is therefore focused on how to ensure contributors are supported while simultaneously keeping various packages up to date and available to the community that depends upon this code for their research. This is partially a result of the software ecosystem being broadly useful to a discipline (Astronomy), as compared to Rosetta Commons, which focused on specific analytic tasks within a subfield of biological engineering (Macromolecular modelling). 
* Continuous annual grant funding and licensing fees allow Rosetta to centralize infrastructure tasks to a core team whose sole job is maintenance. This in turn encourages innovation and expansion of feature sets for labs that are focused solely on producing new research insights. Astropy has, over time, centralized maintenance of the project’s software development and maintenance. But until very recently, this has been a volunteer activity. Shifting time, attention, and energy towards organizing an open-source model of development impacts career trajectories for practicing astronomers, and contributes to a more fragile ecosystem for astronomy.   

We recognize that software sustainability is more than just financial support, but what these case studies make clear is that the economic realities of maintaining and contributing to software development have important downstream impacts that shape innovation and engagement, and the URSSI conceptualization has studied how these challenges can be practically overcome. 

## Winter school

As part of the conceptualization process, in late December 2019 we ran our first ever URSSI school on research software engineering. We began accepting applications in July and received an overwhelming response to our call for applications. For the 30 participant slots available, we received 169 applications, meaning we had a challenging time selecting the participants and had to turn away a large number of interested researchers. While the selection committee used multiple criteria to evaluate and select participants, successful applicants already had some experience with Python programming, Git, and Unix skills, which was  necessary to benefit from the workshop. Our goal wasn't to repeat the same material covered in bootcamps and Software Carpentry style workshops, but to focus on the research software engineering skills that are not formally taught in any setting. These skills include best practices for packaging code as software, testing, collaborative software development, code review, and related topics such as licensing and archiving. The school lasted 2.5 days.

Based on the demand described above, this experience made evident the strong need for the skills covered in the school. The overall feedback from the school was also positive (more on that below). Some key lessons from this pilot that impact our design of a Summer School as part of URSSI are: 1) the school needs to be longer to allow for both discussion time and focused time for students to work on their own code, applying the lessons from the lectures; and 2) the presence of additional helpers outside of the primary instructors was quite beneficial to help answer specific questions from the students.

A few example quotes from the Winter School feedback form include:

* ”I really can't say enough good things about this super empowering workshop! You did an amazing job identifying the things I didn't know that I didn't know, and teaching them at a level that was immediately actionable in my work.”
* “Thank you so much to everyone for taking this amazing initiative to teach young scientists on software sustainability.”
* “Thank you for putting together this winter-school, it was super useful to me and I'm looking forward to applying everything I learned to my future projects and to go deeper into the topics that were covered.”

## Joint Activities

While working to conceptualize URSSI, we helped start two new activities that overlapped our goals, both so that we could promote these goals and also so that we could build up these future partners of a later full URSSI institute.

### Research Software Alliance (ReSA)

URSSI instigated (along with the UK [Software Sustainability Institute](https://software.ac.uk) and [Australian Research Data Commons](https://ardc.edu.au)) a global community of organizations interested in promoting and sustaining software, called the [Research Software Alliance (ReSA)](http://www.researchsoft.org).  ReSA has held three meetings, at RSE18, eScience2018, and RSEConUK19, with representatives from about 20 other organizations, and has assembled a mailing list with about 40 such organizations and an umbrella organization under which all these groups can collaborate to strengthen all of our activities. ReSA is currently working on defining governance and other activities to formalize ReSA, and at the same time, it has started a set of [task forces](http://www.researchsoft.org/resa-taskforces-join-us/) to 1) analyze and document the landscape of different communities and topics of interest for the research software community (e.g., preservation, RSEs, citation, productivity, sustainability), 2) collect and share evidence for the importance of research software, and 3) assemble and maintain a register of research software funding opportunities. Additionally, ReSA is currently working with other members of the scholarly community to start up a task force to define FAIR for software, likely co-organized with [FORCE11](https://www.force11.org/) and [RDA](https://www.rd-alliance.org/).

